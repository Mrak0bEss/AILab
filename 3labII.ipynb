{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tawKmlRrqHf7"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Загрузка данных для классификации\n",
        "classification_data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/AiDatasets/jobDs.csv\")\n",
        "\n",
        "# Предварительная обработка данных\n",
        "classification_data = classification_data.dropna()  # Удаление строк с пропущенными значениями\n",
        "X_text = classification_data['job_title']  # Признаки (текстовые данные)\n",
        "y_class = classification_data['category']  # Целевая переменная\n",
        "\n",
        "# Преобразование текстовых данных в числовые (Bag of Words)\n",
        "vectorizer = CountVectorizer()\n",
        "X_class = vectorizer.fit_transform(X_text)\n",
        "\n",
        "# Разделение данных на обучающую и тестовую выборки\n",
        "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_class, y_class, test_size=0.2, random_state=42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regression_data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/AiDatasets/Delhi_v2.csv\")\n",
        "X_reg = regression_data.drop(columns=[\"price\", \"Address\", \"desc\"])\n",
        "y_reg = regression_data[\"price\"]\n",
        "\n",
        "# Преобразуем категориальные данные в числовые\n",
        "X_reg = pd.get_dummies(X_reg, drop_first=True)\n",
        "\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "nbjQgj2Mvkc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "dt_classifier.fit(X_train_class, y_train_class)\n",
        "\n",
        "# Оценка качества\n",
        "y_pred_class = dt_classifier.predict(X_test_class)\n",
        "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
        "print(f'Accuracy for classification: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niCNykcEvn1M",
        "outputId": "e5a4991b-4643-4123-a5db-abb464bace4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for classification: 0.7923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
        "dt_regressor.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "\n",
        "# Прогнозирование для регрессора\n",
        "y_pred_reg = dt_regressor.predict(X_test_reg)\n",
        "\n",
        "# Оценка качества\n",
        "mae = mean_absolute_error(y_test_reg, y_pred_reg)\n",
        "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
        "r2 = r2_score(y_test_reg, y_pred_reg)\n",
        "\n",
        "# Вывод метрик\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"R^2: {r2:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGu868invqwg",
        "outputId": "9a333ebd-df96-473b-a9aa-6e10fc62015f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 230981.9121\n",
            "MSE: 822028294573.6434\n",
            "R^2: 0.9861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor\n",
        "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Препроцессинг данных (масштабирование, замещение пропусков)\n",
        "X_train_class_dense = X_train_class.toarray()  # Преобразуем разреженную матрицу в плотную\n",
        "X_test_class_dense = X_test_class.toarray()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_class_dense)\n",
        "X_test_scaled = scaler.transform(X_test_class_dense)\n",
        "\n",
        "# Замещение пропусков (если есть)\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_imputed = imputer.fit_transform(X_train_class)\n",
        "X_test_imputed = imputer.transform(X_test_class)\n",
        "\n",
        "# Масштабирование данных\n",
        "scaler = StandardScaler(with_mean=False)  # Без центрирования для разреженных матриц\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
        "X_test_scaled = scaler.transform(X_test_imputed)\n",
        "\n",
        "# Подбор гиперпараметров через GridSearchCV с уменьшением диапазона\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 150],  # Меньше деревьев\n",
        "    'max_depth': [10, 15],  # Меньше значений max_depth\n",
        "    'min_samples_split': [2, 4]  # Меньше значений min_samples_split\n",
        "}\n",
        "\n",
        "rf_classifier = RandomForestClassifier(random_state=42, n_jobs=-1)  # Используем все ядра процессора для ускорения\n",
        "grid_search_rf = GridSearchCV(rf_classifier, param_grid, cv=3, n_jobs=-1)  # Меньше кросс-валидаций для ускорения\n",
        "grid_search_rf.fit(X_train_scaled, y_train_class)\n",
        "\n",
        "# Лучшие гиперпараметры\n",
        "print(\"Best parameters for Random Forest:\", grid_search_rf.best_params_)\n",
        "\n",
        "# Оценка качества модели на тестовых данных\n",
        "y_pred_class_rf = grid_search_rf.best_estimator_.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test_class, y_pred_class_rf)\n",
        "\n",
        "print(\"Accuracy of the model:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K7nCmfWwBaI",
        "outputId": "ed9e984e-f6cd-4990-d64a-49fba9b04559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters for Random Forest: {'max_depth': 15, 'min_samples_split': 4, 'n_estimators': 100}\n",
            "Accuracy of the model: 0.6926994906621392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Препроцессинг данных\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "X_train_imputed = imputer.fit_transform(X_train_reg)\n",
        "X_test_imputed = imputer.transform(X_test_reg)\n",
        "\n",
        "# Подбор гиперпараметров\n",
        "param_dist = {\n",
        "    \"max_depth\": [3, 5, 10, 20, None],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 4],\n",
        "    \"max_features\": [\"sqrt\", \"log2\", None],  # Убрали \"auto\"\n",
        "}\n",
        "\n",
        "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
        "random_search = RandomizedSearchCV(\n",
        "    dt_regressor,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,\n",
        "    cv=3,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    error_score=\"raise\"  # Прерываем при ошибках\n",
        ")\n",
        "\n",
        "# Обучение\n",
        "random_search.fit(X_train_imputed, y_train_reg)\n",
        "\n",
        "# Лучшие гиперпараметры\n",
        "print(\"Лучшие параметры решающего дерева для регрессии:\", random_search.best_params_)\n",
        "\n",
        "# Оценка модели\n",
        "best_dt_regressor = random_search.best_estimator_\n",
        "y_pred = best_dt_regressor.predict(X_test_imputed)\n",
        "\n",
        "mae = mean_absolute_error(y_test_reg, y_pred)\n",
        "mse = mean_squared_error(y_test_reg, y_pred)\n",
        "r2 = r2_score(y_test_reg, y_pred)\n",
        "\n",
        "print(f\"MAE: {mae}\")\n",
        "print(f\"MSE: {mse}\")\n",
        "print(f\"R^2: {r2}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvobLS-eywim",
        "outputId": "461aa5a1-c9f0-40cc-8c51-0481b9a245c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры решающего дерева для регрессии: {'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': None}\n",
            "MAE: 268841.920963045\n",
            "MSE: 961635486634.9545\n",
            "R^2: 0.9837790886889036\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Кастомный классификатор решающим деревом"
      ],
      "metadata": {
        "id": "Uya3nwxyJQhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "class DecisionTreeClassifierCustom:\n",
        "    def __init__(self, max_depth=None, min_samples_split=2, min_samples_leaf=1):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        if isinstance(X, csr_matrix):\n",
        "            X = X.toarray()  # Преобразуем разреженную матрицу в плотную\n",
        "        self.tree = self._build_tree(X, y)\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        n_samples, n_features = X.shape\n",
        "        unique_classes = np.unique(y)\n",
        "\n",
        "        # Прекращаем рекурсию, если все классы одинаковы, или максимальная глубина достигнута\n",
        "        if len(unique_classes) == 1 or (self.max_depth and depth >= self.max_depth):\n",
        "            return Counter(y).most_common(1)[0][0]\n",
        "\n",
        "        # Ищем лучший раздел\n",
        "        best_split = self._best_split(X, y)\n",
        "        if best_split is None:\n",
        "            return Counter(y).most_common(1)[0][0]\n",
        "\n",
        "        left_tree = self._build_tree(X[best_split['left_indices']], y[best_split['left_indices']], depth + 1)\n",
        "        right_tree = self._build_tree(X[best_split['right_indices']], y[best_split['right_indices']], depth + 1)\n",
        "        return {'feature_index': best_split['feature_index'], 'threshold': best_split['threshold'], 'left': left_tree, 'right': right_tree}\n",
        "\n",
        "    def _best_split(self, X, y):\n",
        "        best_gini = float(\"inf\")\n",
        "        best_split = {}\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        for feature_index in range(n_features):\n",
        "            thresholds = np.unique(X[:, feature_index])\n",
        "            for threshold in thresholds:\n",
        "                left_indices = X[:, feature_index] <= threshold\n",
        "                right_indices = X[:, feature_index] > threshold\n",
        "\n",
        "                # Преобразуем индексы в булевы массивы для разреженных данных\n",
        "                if isinstance(left_indices, csr_matrix):\n",
        "                    left_indices = left_indices.toarray().astype(bool)\n",
        "                if isinstance(right_indices, csr_matrix):\n",
        "                    right_indices = right_indices.toarray().astype(bool)\n",
        "\n",
        "                # Пропускаем маленькие разделы\n",
        "                if np.sum(left_indices) < self.min_samples_leaf or np.sum(right_indices) < self.min_samples_leaf:\n",
        "                    continue\n",
        "\n",
        "                gini = self._gini_index(y[left_indices], y[right_indices])\n",
        "\n",
        "                if gini < best_gini:\n",
        "                    best_gini = gini\n",
        "                    best_split = {'feature_index': feature_index, 'threshold': threshold, 'left_indices': left_indices, 'right_indices': right_indices}\n",
        "\n",
        "        return best_split if best_gini != float(\"inf\") else None\n",
        "\n",
        "    def _gini_index(self, left_y, right_y):\n",
        "        left_size = len(left_y)\n",
        "        right_size = len(right_y)\n",
        "        total_size = left_size + right_size\n",
        "        left_prob = np.array([np.sum(left_y == c) / left_size for c in np.unique(left_y)])\n",
        "        right_prob = np.array([np.sum(right_y == c) / right_size for c in np.unique(right_y)])\n",
        "        gini_left = 1 - np.sum(left_prob ** 2)\n",
        "        gini_right = 1 - np.sum(right_prob ** 2)\n",
        "        return (left_size / total_size) * gini_left + (right_size / total_size) * gini_right\n",
        "\n",
        "    def predict(self, X):\n",
        "        if isinstance(X, csr_matrix):\n",
        "            X = X.toarray()  # Преобразуем разреженную матрицу в плотную\n",
        "        return np.array([self._predict_sample(x, self.tree) for x in X])\n",
        "\n",
        "    def _predict_sample(self, x, tree):\n",
        "        if not isinstance(tree, dict):\n",
        "            return tree\n",
        "\n",
        "        if x[tree['feature_index']] <= tree['threshold']:\n",
        "            return self._predict_sample(x, tree['left'])\n",
        "        else:\n",
        "            return self._predict_sample(x, tree['right'])"
      ],
      "metadata": {
        "id": "2tgUTf6FCg0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = DecisionTreeClassifierCustom(max_depth=5, min_samples_split=10, min_samples_leaf=5)\n",
        "\n",
        "# Обучение\n",
        "classifier.fit(X_train_class, y_train_class)\n",
        "\n",
        "# Прогнозирование\n",
        "y_pred = classifier.predict(X_test_class)\n",
        "\n",
        "# Оценка качества\n",
        "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlKTmQd4CiZc",
        "outputId": "e6d75740-3355-4cc0-c9b1-0b4763511260"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7923033389926429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Кастомная регрессия решающим дереовм"
      ],
      "metadata": {
        "id": "kvpZyoj2JXsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecisionTreeRegressorCustom:\n",
        "    def __init__(self, max_depth=None, min_samples_split=2, min_samples_leaf=1):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.tree = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build_tree(X, y)\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        n_samples, n_features = X.shape\n",
        "        unique_values = np.unique(y)\n",
        "\n",
        "        # Условие остановки\n",
        "        if len(unique_values) == 1:\n",
        "            return {'value': unique_values[0]}\n",
        "\n",
        "        if depth >= self.max_depth or n_samples < self.min_samples_split:\n",
        "            return {'value': np.mean(y)}\n",
        "\n",
        "        # Поиск лучшего разбиения\n",
        "        best_split = None\n",
        "        best_score = float('inf')\n",
        "        for feature_index in range(n_features):\n",
        "            thresholds = np.unique(X[:, feature_index])\n",
        "            for threshold in thresholds:\n",
        "                left_indices = X[:, feature_index] <= threshold\n",
        "                right_indices = ~left_indices\n",
        "                left_y = y[left_indices]\n",
        "                right_y = y[right_indices]\n",
        "\n",
        "                if len(left_y) >= self.min_samples_leaf and len(right_y) >= self.min_samples_leaf:\n",
        "                    gini = self._calculate_gini(left_y, right_y)\n",
        "                    if gini < best_score:\n",
        "                        best_score = gini\n",
        "                        best_split = (feature_index, threshold)\n",
        "\n",
        "        if best_split is None:\n",
        "            return {'value': np.mean(y)}\n",
        "\n",
        "        feature_index, threshold = best_split\n",
        "        left_indices = X[:, feature_index] <= threshold\n",
        "        right_indices = ~left_indices\n",
        "        left_tree = self._build_tree(X[left_indices], y[left_indices], depth + 1)\n",
        "        right_tree = self._build_tree(X[right_indices], y[right_indices], depth + 1)\n",
        "\n",
        "        return {'feature_index': feature_index, 'threshold': threshold, 'left': left_tree, 'right': right_tree}\n",
        "\n",
        "    def _calculate_gini(self, left_y, right_y):\n",
        "        left_size = len(left_y)\n",
        "        right_size = len(right_y)\n",
        "        total_size = left_size + right_size\n",
        "        left_gini = 1 - sum((np.sum(left_y == label) / left_size) ** 2 for label in np.unique(left_y))\n",
        "        right_gini = 1 - sum((np.sum(right_y == label) / right_size) ** 2 for label in np.unique(right_y))\n",
        "        return (left_size / total_size) * left_gini + (right_size / total_size) * right_gini\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = [self._predict_sample(sample, self.tree) for sample in X]\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def _predict_sample(self, sample, tree):\n",
        "        if 'value' in tree:\n",
        "            return tree['value']\n",
        "\n",
        "        feature_value = sample[tree['feature_index']]\n",
        "        if feature_value <= tree['threshold']:\n",
        "            return self._predict_sample(sample, tree['left'])\n",
        "        else:\n",
        "            return self._predict_sample(sample, tree['right'])"
      ],
      "metadata": {
        "id": "LDRJtYiOJdfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regressor = DecisionTreeRegressorCustom(max_depth=5, min_samples_split=10, min_samples_leaf=5)\n",
        "regressor.fit(X_train_reg.values, y_train_reg.values)\n",
        "\n",
        "# Прогнозируем и оцениваем\n",
        "y_pred = regressor.predict(X_test_reg.values)\n",
        "\n",
        "# Оценка качества модели\n",
        "mae = mean_absolute_error(y_test_reg, y_pred)\n",
        "mse = mean_squared_error(y_test_reg, y_pred)\n",
        "\n",
        "print(f\"MAE: {mae}\")\n",
        "print(f\"MSE: {mse}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr4uNqEDJ66j",
        "outputId": "79293ad6-6539-4dde-db74-b55a688b43fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-47e252df4b0b>:28: RuntimeWarning: invalid value encountered in less_equal\n",
            "  left_indices = X[:, feature_index] <= threshold\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 1258357.4966011762\n",
            "MSE: 11770383511829.137\n"
          ]
        }
      ]
    }
  ]
}